<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>How to install Kubeflow 1.2 on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Lvgqj4tFZM4/how-install-kubeflow-12-red-hat-openshift" /><author><name>David Marcus</name></author><id>78521b1a-011c-4ff6-b07a-3c5e1142b49e</id><updated>2021-05-28T07:00:00Z</updated><published>2021-05-28T07:00:00Z</published><summary type="html">&lt;p&gt;As artificial intelligence (AI) adoption increases across industries, particularly through machine learning (ML), the job of integrating the often disparate tools, libraries, packages, and dependencies also increases in complexity. This makes development and operations (&lt;a href="https://developers.redhat.com/topics/devops"&gt;DevOps&lt;/a&gt;) a daunting task that both organizations and open source communities are actively working on. To quote the authors of &lt;a href="https://web.kaust.edu.sa/Faculty/MarcoCanini/classes/CS290E/F19/papers/tech-debt.pdf"&gt;Hidden Technical Debt in Machine Learning Systems&lt;/a&gt;, "developing and deploying ML systems is relatively fast and cheap, but maintaining them over time is difficult and expensive."&lt;/p&gt; &lt;p&gt;If you are in the throes of tackling DevOps for &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;AI/ML&lt;/a&gt; (MLOps), two open source projects worth your attention are the upstream &lt;a href="https://www.kubeflow.org/"&gt;Kubeflow&lt;/a&gt; and the downstream &lt;a href="https://opendatahub.io/"&gt;Open Data Hub&lt;/a&gt; (ODH). The goal of these projects is to provide machine learning toolkits that handle the complex parts of orchestration that traditional software DevOps does not.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: For more about MLOps, see, &lt;a href="https://www.openshift.com/blog/dotscience-on-openshift"&gt;Dotscience on OpenShift: Enabling DevOps for MLOps&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As the name indicates, Kubeflow is based on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. In this article, we'll show it running on &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; and include an &lt;a href="https://developers.redhat.com/topics/service-mesh"&gt;Istio service mesh&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Objective&lt;/h2&gt; &lt;p&gt;Use this article as a startup procedure to install a default Kubeflow toolkit on an OpenShift Container Platform instance to explore the tools and capabilities. Figure 1 shows the Kubeflow dashboard running on OpenShift Container Platform, providing access to a suite of machine learning tools that span the system life cycle.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-ui.png?itok=G5FBZdI9" width="600" height="444" alt="Screenshot of the kubeflow central dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Kubeflow central dashboard. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Kubeflow central dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The latest release of Kubeflow at the time of this writing incorporates changes to the file structure for distribution-specific platforms, such as OpenShift. If you are interested in the details, you can read the source &lt;a href="https://github.com/kubeflow/manifests/pull/1739"&gt;pull request&lt;/a&gt; that explains the reason for the change.&lt;/p&gt; &lt;h3&gt;Overview of major steps&lt;/h3&gt; &lt;p&gt;The following list summarizes the steps needed to get Kubeflow running on OpenShift Container Platform:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Install the Open Data Hub Operator.&lt;/li&gt; &lt;li&gt;Create the Kubeflow project.&lt;/li&gt; &lt;li&gt;Install Kubeflow.&lt;/li&gt; &lt;li&gt;Monitor the installation.&lt;/li&gt; &lt;li&gt;Access the Kubeflow user interface (UI).&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;Requirements&lt;/h3&gt; &lt;p&gt;To use Kubeflow as shown in this article, please note the following requirements:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;You &lt;em&gt;must&lt;/em&gt; have an OpenShift Container Platform cluster 4.2+ installed with cluster admin privileges.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;should not&lt;/em&gt; have an &lt;a href="https://istio.io/latest/docs/ops/deployment/deployment-models/#multiple-meshes"&gt;existing Istio service mesh&lt;/a&gt;, because it will lead to name collisions.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;should not&lt;/em&gt;have an existing project named &lt;code&gt;istio-system&lt;/code&gt; as &lt;a href="https://www.kubeflow.org/docs/external-add-ons/istio/istio-in-kubeflow/"&gt;Kubeflow deploys Istio along with configurations&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;You &lt;em&gt;must not&lt;/em&gt; have remaining mutating webhooks or validating webhooks from prior tests.&lt;/li&gt; &lt;li&gt; &lt;p&gt;You &lt;em&gt;must not&lt;/em&gt; deploy Kubeflow in a project or namespace other than &lt;code&gt;kubeflow&lt;/code&gt;.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Running on an OpenShift cluster&lt;/h2&gt; &lt;p&gt;Here are some options for getting access to an OpenShift cluster to run through the procedure in this article. Getting a cluster running is beyond the scope of the tutorial, but the resources in this section offer a starting point.&lt;/p&gt; &lt;h3&gt;On your local machine cluster (recommended)&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt; is designed to run on a local computer to simplify setup and testing. The product emulates the cloud development environment with all of the tools needed to develop container-based applications.&lt;/p&gt; &lt;h3&gt;On a 60-minute temporary cluster (only for learning)&lt;/h3&gt; &lt;p&gt;&lt;a href="https://www.katacoda.com/openshift/courses/playgrounds/"&gt;Katacoda&lt;/a&gt; offers an OpenShift cluster as a playground that can be used to perform this installation, as long as you complete the task in an hour or less. It can be done.&lt;/p&gt; &lt;h3&gt;More options&lt;/h3&gt; &lt;p&gt;See the &lt;a href="https://www.openshift.com/try"&gt;OpenShift trial page&lt;/a&gt; for other options.&lt;/p&gt; &lt;h2&gt;Installing the Open Data Hub Operator&lt;/h2&gt; &lt;p&gt;Kubeflow should be installed on OpenShift using the Open Data Hub Operator from the &lt;a href="https://catalog.redhat.com/software/operators/explore"&gt;OpenShift Operators catalog&lt;/a&gt;. The upstream Kubeflow Operator from &lt;a href="http://operatorhub.io"&gt;OperatorHub.io&lt;/a&gt; will not run successfully on OpenShift because it is intended for a general-purpose Kubernetes cluster.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Operators&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;OperatorHub&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Search for "Open Data Hub."&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub Operator&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Continue&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Accept the default installation strategy, which uses the following settings: &lt;ul&gt;&lt;li&gt;Update Channel: beta&lt;/li&gt; &lt;li&gt;Installation mode: All namespaces on the cluster (default)&lt;/li&gt; &lt;li&gt;Installed Namespace: &lt;code&gt;openshift-operators&lt;/code&gt;&lt;/li&gt; &lt;li&gt;Approval strategy: Automatic&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Install&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 2 illustrates the Open Data Hub Operator selection from the OpenShift OperatorHub.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-install.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-install.png?itok=piT5UOJ3" width="600" height="307" alt="Screenshot of Open Data Hub Operator install from the Red Hat OpenShift OperatorHub" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Open Data Hub Operator install. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Open Data Hub Operator installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Creating the Kubeflow project&lt;/h2&gt; &lt;p&gt;Kubeflow must be installed in a namespace called &lt;code&gt;kubeflow&lt;/code&gt;. A request for an alternative namespace is an &lt;a href="https://github.com/kubeflow/kubeflow/issues/5647"&gt;open issue&lt;/a&gt; at the time of this writing.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Home&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Projects&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create Project&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Set the following values: &lt;ul&gt;&lt;li&gt;Name: &lt;code&gt;kubeflow&lt;/code&gt; (cannot be altered)&lt;/li&gt; &lt;li&gt;Display Name: &lt;code&gt;kubeflow&lt;/code&gt; (unlike the previous name, you can choose another value here)&lt;/li&gt; &lt;li&gt;Description: Kubeflow ML toolkit (you can choose another value)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;Change to the &lt;code&gt;kubeflow&lt;/code&gt; project.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Operators—&gt;Installed Operators&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Wait for the Operator to display "Succeeded" in the Status field.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 3 displays the expected result when the operator is completely installed.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-succeeded.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-succeeded.png?itok=Hovsw1gE" width="600" height="191" alt="Screenshot of Open Data Hub Operator with a succeeded status" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: ODH Operator successful installation. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: A succesful installation of the Open Data Hub Operator.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Installing Kubeflow&lt;/h2&gt; &lt;p&gt;By default, the Open Data Hub Operator includes a manifest that lets you try out different components for MLOps. Because the toolset used in this article is different from the one in the default manifest, you should paste in a different manifest.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Click the &lt;strong&gt;Open Data Hub Operator&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; link under &lt;strong&gt;Provided APIs&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create KfDef&lt;/strong&gt; button.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;YAML View&lt;/strong&gt; radio button.&lt;/li&gt; &lt;li&gt;Delete all the YAML code.&lt;/li&gt; &lt;li&gt;Copy and paste in all the YAML code from &lt;a href="https://raw.githubusercontent.com/kubeflow/manifests/master/distributions/kfdef/kfctl_openshift.v1.2.0.yaml"&gt;kfctl_openshift.v1.2.0.yaml&lt;/a&gt;. &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For reference, the HTML version can be found on &lt;a href="https://github.com/kubeflow/manifests/tree/master/distributions/kfdef"&gt;Kubeflow GitHub manifests&lt;/a&gt;.&lt;/p&gt; &lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Create&lt;/strong&gt; button.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 4 shows the Provided APIs selection.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/odh-api.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/odh-api.png?itok=V9y8Mcio" width="600" height="190" alt="Screenshot of the provided API for selection to create a KfDef and edit YAML" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Open Data Hub Provide API. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Open Data Hub Provided APIs.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 5 shows the YAML code you will replace.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kfctl-yaml.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kfctl-yaml.png?itok=nEXuGo9_" width="600" height="444" alt="Screenshot of the YAML View to replace existing YAML with provided YAML for Kubeflow" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: ODH Provided API KfDef YAML View. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: Open Data Hub Provided API KfDef YAML View.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Monitoring the installation&lt;/h2&gt; &lt;p&gt;In the background, the Open Data Hub Operator performs the commands a system administrator would execute on the command line to install Kubeflow, such as &lt;code&gt;kfctl build -f...&lt;/code&gt; and &lt;code&gt;kfctl apply -f...&lt;/code&gt; The web console doesn't show when the installation is complete, so this section shows a few ways to monitor the installation. If all the pods are running without errors, the installation is complete.&lt;/p&gt; &lt;h3&gt;Monitoring from the administrator perspective&lt;/h3&gt; &lt;p&gt;Streaming events are a great way to get a sense of what major activity is occurring after an action such as a deployment. To view the events:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to &lt;strong&gt;Home&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Section the project: either &lt;code&gt;kubeflow&lt;/code&gt; to see just events for Kubeflow, or "All projects" to see the multiple projects being updated during installation.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Events&lt;/strong&gt; to monitor the deployment events stream.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 6 shows the events streaming during an installation in the &lt;code&gt;kubeflow&lt;/code&gt; project.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/events.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/events.png?itok=oi84DHiL" width="600" height="289" alt="Screenshot of the event stream during a new kubeflow installation" title="Project kubeflow event stream" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: Event stream during installation &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Event stream during installation.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Workload status and alerts are a quick way to understand how progress is going. To view the workloads:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Projects&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;code&gt;kubeflow&lt;/code&gt; project link.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Workloads&lt;/strong&gt; menu item in the body of the screen to review pods.&lt;/li&gt; &lt;li&gt;Investigate workloads that don't self-correct (give them time to auto-correct).&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 7 shows workloads from the project overview page. Workloads in the project are also viewable from the vertical menu.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/overview.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/overview.png?itok=OE9glwyg" width="600" height="444" alt="Screenshot of the workloads from the project overview page" title="Kubeflow Workload Overview" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Kubeflow project Workloads overview &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Overview of the Kubeflow project workloads.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A project called &lt;code&gt;cert-manager&lt;/code&gt; gets created during installation. Its events and pods provide good insight. To view these events or pods:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: cert-manager&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Events&lt;/strong&gt; to review events. Under &lt;strong&gt;Workloads&lt;/strong&gt;, click &lt;strong&gt;Pods&lt;/strong&gt; to review pods.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 8 shows the pods for &lt;code&gt;cert-manager&lt;/code&gt;.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/cert-manager.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/cert-manager.png?itok=8DCGiju1" width="600" height="213" alt="Screenshot of the pods in the cert-manager project that gets created" title="Cert-manager project pods" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: Project cert-manager pods status &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: Status of pods in the cert-manager pods status.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Another important project, &lt;code&gt;istio-system&lt;/code&gt;, is created during installation. This project hosts the Istio service mesh that handles all the networking between the services. To view the project:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Under &lt;strong&gt;Home&lt;/strong&gt;, click &lt;strong&gt;Events&lt;/strong&gt; to review events. Under &lt;strong&gt;Workloads&lt;/strong&gt;, click &lt;strong&gt;Pods&lt;/strong&gt; to review pods. Under &lt;strong&gt;Networking&lt;/strong&gt;, click &lt;strong&gt;Routes&lt;/strong&gt; to access the URL to the Kubeflow central dashboard.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 9 shows the routes in the project.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/istio-route.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/istio-route.png?itok=PFfmkJTw" width="600" height="323" alt="Screenshot of the istio ingress gateway route to access kubeflow interface" title="Project istio-system routes" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: Istio-system route for istio-ingressgateway &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: istio-system route for the istio-ingress gateway.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Monitoring from the developer perspective&lt;/h3&gt; &lt;p&gt;In addition to the administrator perspective, a developer perspective abstracts infrastructure features out of view to leave an uncluttered developer experience. To see this perspective:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Go to the &lt;strong&gt;developer&lt;/strong&gt; perspective.&lt;/li&gt; &lt;li&gt;Select &lt;strong&gt;Project: kubeflow&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Topology&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 10 shows the results.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kfctl-topology.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kfctl-topology.png?itok=fLwITOUL" width="600" height="426" alt="Screenshot of the app topology created in the kubeflow project" title="Developer Perspective Topology View" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: Developer Perspective kubeflow project topology &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: Kubeflow project topology in the developer perspective.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If there are no errors across the projects and the Kubeflow UI launches, the installation has succeeded.&lt;/p&gt; &lt;h2&gt;Accessing the Kubeflow UI&lt;/h2&gt; &lt;p&gt;This section offers two ways to access the Kubeflow central dashboard from the web console. For reference, a command-line query would look like:&lt;/p&gt; &lt;pre&gt; # oc get routes -n istio-system istio-ingressgateway -o jsonpath='http://{.spec.host}/' &lt;/pre&gt; &lt;h3&gt;Going to the dashboard from the administrator perspective&lt;/h3&gt; &lt;p&gt;From the administrator perspective, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Networking&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Routes&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the location URL &lt;code&gt;http://istio-ingressgateway...&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 11 shows how to find the location URL.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-dashboard.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-dashboard.png?itok=xGlofgx1" width="600" height="224" alt="Screenshot of the kubeflow dashboard route in the istio-system project" title="Route to Kubeflow Dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: Route to Kubeflow Dashboard in the istio-system project &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11: Route to the Kubeflow dashboard in the istio-system project.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Going to the dashboard from the developer perspective&lt;/h3&gt; &lt;p&gt;From the developer perspective, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project: istio-system&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Go to &lt;strong&gt;Topology&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Search for "istio-ingressgateway."&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open URL&lt;/strong&gt; arrow icon, or click the &lt;code&gt;istio-ingressgateway&lt;/code&gt; pod and the URL under &lt;strong&gt;Resources—&gt;Routes&lt;/strong&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;Figure 12 shows the location of the URL.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-route.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-route.png?itok=8JfpGtYM" width="600" height="416" alt="Screenshot of the app topology of the istio-system project to access Kubeflow dashboard" title="Kubeflow Topology Route" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: Developer Perspective route to Kubeflow from istio-system project &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: Developer perspective route to Kubeflow from istio-system project.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Viewing the Kubeflow central dashboard&lt;/h3&gt; &lt;p&gt;Once you complete the registration process and create a namespace, you will see a dashboard like the one in Figure 13.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/kubeflow-ui.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/kubeflow-ui.png?itok=G5FBZdI9" width="600" height="444" alt="Screenshot of the kubeflow central dashboard" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The Kubeflow central dashboard. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 13: The Kubeflow central dashboard.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Uninstalling Kubeflow&lt;/h2&gt; &lt;p&gt;No proper installation procedure is truly complete without an uninstallation procedure.&lt;/p&gt; &lt;p&gt;As an administrator from the OpenShift web console, do the following:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Select &lt;strong&gt;Project kubeflow&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; Operator.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Open Data Hub&lt;/strong&gt; link under &lt;strong&gt;Provided APIs&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Click the &lt;strong&gt;Kebab&lt;/strong&gt; button (the one with three vertical dots) for your &lt;code&gt;kubeflow&lt;/code&gt; instance.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Delete KfDef&lt;/strong&gt; to begin the delete process for your &lt;code&gt;kubeflow&lt;/code&gt; instance.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;The procedure in this article illustrates a best practice you can follow to install Kubeflow on Red Hat OpenShift using the Open Data Hub Operator. The manifest file used provides an example toolkit from the Kubeflow project that you can fork, modify, and update to fit your production MLOps needs. Furthermore, the &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operator framework&lt;/a&gt; simplifies installation, operations, and maintenance as the community &lt;a href="https://opendatahub.io/docs/roadmap/future.html"&gt;continues to publish enhancements&lt;/a&gt; to both the operator and machine learning tooling in conjunction with the overall &lt;a href="https://www.openshift.com/learn/topics/ai-ml"&gt;benefits of AI/ML on Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/28/how-install-kubeflow-12-red-hat-openshift" title="How to install Kubeflow 1.2 on Red Hat OpenShift"&gt;How to install Kubeflow 1.2 on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Lvgqj4tFZM4" height="1" width="1" alt=""/&gt;</summary><dc:creator>David Marcus</dc:creator><dc:date>2021-05-28T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/28/how-install-kubeflow-12-red-hat-openshift</feedburner:origLink></entry><entry><title>How to update to newer Red Hat OpenShift 4 releases</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Q17YrPMCT1I/how-update-newer-red-hat-openshift-4-releases" /><author><name>Fernando Lozano</name></author><id>9ecbbc93-71a1-49f1-b629-956f00987bbb</id><updated>2021-05-27T07:00:00Z</updated><published>2021-05-27T07:00:00Z</published><summary type="html">&lt;p&gt;This article demonstrates two common scenarios for updating &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift 4&lt;/a&gt;: to a newer z-stream release and to a newer minor release. I include plenty of screenshots of actual updates from 4.5.4 to 4.5.17 and then to 4.6.4, so you know what to expect when you make these updates yourself.&lt;/p&gt; &lt;p&gt;OpenShift 4 makes the update process easy and provides a number of safety features to minimize the risk of a failed outcome. Still, updating OpenShift clusters can be scary the first time. This article shows how two perform typical update scenarios, step-by-step:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Updating between two z-stream releases, from 4.y.z to 4.y.z+d. Note that you can skip z-stream releases during an update.&lt;/li&gt; &lt;li&gt;Updating between two minor releases, from 4.y to 4.y+1. Note that you cannot skip a minor release during an update.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;To use or not to use the web console&lt;/h2&gt; &lt;p&gt;The update process, including web console pages and quirks, is mostly the same for earlier minor releases, for example a z-stream update of OpenShift 4.4. OpenShift 4.6 includes significant improvements to its web console that solve most if not all of the gotchas that I demonstrate in this article.&lt;/p&gt; &lt;p&gt;You can perform the entire cluster update process from the command-line interface (CLI) and automate it using Ansible playbooks, shell scripts, or whatever you like. If you need instructions about how to perform a cluster update using the CLI, please refer to the &lt;a href="https://docs.openshift.com/container-platform/4.5/updating/updating-cluster-cli.html"&gt;Red Hat OpenShift Container Platform product documentation&lt;/a&gt; and this &lt;a href="https://access.redhat.com/solutions/4606811"&gt;article from the OpenShift knowledgebase&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you have a test cluster that you were considering updating for some time and did not, for fear of the outcome, you can use the cluster now to follow the instructions from this article.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Do not try to update a &lt;a href="https://developers.redhat.com/products/codeready-containers"&gt;Red Hat CodeReady Containers&lt;/a&gt; (CRC) single-node cluster. CodeReady Containers disables some of the cluster operators required for a successful update in order to reduce its hardware requirements, and the OpenShift update process was not designed to work with a single supervisor node, anyway. Later releases of &lt;a href="https://developers.redhat.com/courses/openshift/getting-started"&gt;OpenShift Container Platform&lt;/a&gt; will support single-node OpenShift (SNO) clusters, which follow a different design and installation process from CodeReady Containers. SNO clusters will support updates when they become generally available.&lt;/p&gt; &lt;p&gt;Because the set of available updates and paths changes from time to time, you might not be able to follow the instructions in this article exactly as written. You might start from a different release, target a different final release, and have to pass through different intermediate releases. I hope to provide you with sufficient information to extrapolate to your specific scenario.&lt;/p&gt; &lt;h2&gt;What is the current version of my OpenShift cluster?&lt;/h2&gt; &lt;p&gt;Open your OpenShift web console, log in with cluster administrator rights, and choose &lt;strong&gt;Administration—&gt;Cluster Settings&lt;/strong&gt;. You should see a page that displays your cluster’s current update channel and OpenShift release. Mine is using the somewhat old 4.5.4 release, as shown in Figure 1. I have not updated my test cluster since it was first installed a while ago.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-1-version-4.5.4-2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-1-version-4.5.4-2.png?itok=SzbKg03Q" width="600" height="234" title="blog-1-version-4.5.4" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Viewing the current cluster settings.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If I click on the pen icon beside my current update channel, which is stable-4.5, the web console allows me to choose only from other channels of the same OpenShift release (see Figure 2). That means that my current release cannot be immediately updated to the next minor release—at least not using the web console.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-2-no-4.5-channel.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-2-no-4.5-channel.png?itok=o8Dt20bt" width="600" height="338" title="blog-2-no-4.5-channel" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Available channels for updates.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For now, do not change the update channel.&lt;/p&gt; &lt;h2&gt;Why don't I see the channel for the next minor OpenShift release?&lt;/h2&gt; &lt;p&gt;It might be possible to update directly to an OpenShift 4.6.x release from the CLI, but up to OpenShift 4.5, the web console comes with a hardcoded list of candidate update channels. The initial z-stream releases hard-code just their own update channels. Later z-stream releases add channels of the next minor release.&lt;/p&gt; &lt;p&gt;OpenShift 4.6 changes the offerings so that the list of available update channels becomes dynamic and shows channels from new releases as they become available. That means that an early 4.6.z release might become updatable to 4.7 without passing through intermediate 4.6.z releases, using the web console.&lt;/p&gt; &lt;p&gt;As I am still on 4.5 and I wish to follow the easy user interface (UI) provided by the web console, I have to first update to a newer 4.5.z release. Shame on me for leaving my cluster for so long without bug fixes and security updates! That is about to be corrected.&lt;/p&gt; &lt;p&gt;If I were in a hurry to update to OpenShift 4.6, or maybe to a very recent 4.5.x release, for example to get the fix for a critical bug that is affecting my production users, I might have to switch to a fast channel. Updates to OpenShift 4 are made available first in the fast channel. Only after a number of customers successfully run a given release without major incidents is an update added to the stable channel.&lt;/p&gt; &lt;p&gt;OpenShift update channels and upgrade paths contain many more nuances than I explain in this article. For deeper information about how Red Hat manages OpenShift update channels and releases, refer to &lt;a href="https://www.openshift.com/blog/the-ultimate-guide-to-openshift-release-and-upgrade-process-for-cluster-administrators"&gt;The Ultimate Guide to OpenShift Release and Upgrade Process for Cluster Administrators&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Updating to a newer z-stream release&lt;/h2&gt; &lt;p&gt;My test cluster is running release 4.5.4 and using the stable-4.5 channel. If I click &lt;strong&gt;Update now&lt;/strong&gt;, the web console presents me a list of releases that I can update to, with the more recent releases shown first (see Figure 3).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-3-update-to-4.5.17.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-3-update-to-4.5.17.png?itok=XFQi75B7" width="600" height="522" title="blog-3-update-to-4.5.17" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Selecting a version of OpenShift to update to after "Update now".&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Remember that the screenshot represents a point in time, in this case November 2020. You might see more (or fewer!) releases when you view them yourself.&lt;/p&gt; &lt;p&gt;The list might not include the latest release from your current channel. It includes only the ones with a direct update path from your current release. A few update cycles might take place before you get to the release you want or run out of update paths.&lt;/p&gt; &lt;p&gt;I select the 4.5.17 release, which is the latest as I write this article, and click &lt;strong&gt;Update&lt;/strong&gt;. After a few moments, the web console starts displaying the status of my update, as shown in Figure 4.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-4-working-to-4.5.17.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-4-working-to-4.5.17.png?itok=p7pJZDiv" width="600" height="225" title="blog-4-working-to-4.5.17" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: The update status.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The time to update depends on a number of factors, such as your internet bandwidth, size of the &lt;a href="https://developers.redhat.com/products/rhel "&gt;Red Hat Enterprise Linux&lt;/a&gt; CoreOS images and cluster operator images, number of nodes on your cluster, number of applications, their disruption budgets, and many other factors. My compact test cluster (only three nodes) took about 40 minutes.&lt;/p&gt; &lt;h2&gt;Web console quirks while updating&lt;/h2&gt; &lt;p&gt;During updates I saw a couple of times that the percent-complete indicator moved backward, for example from 70% to 25%. Don’t panic if that happens to you. I also saw a few temporary failures that disappeared without action from me, which I will explain later in this article. The upstream &lt;a href="https://github.com/openshift/cluster-version-operator/blob/master/docs/dev/upgrades.md#why-does-the-openshift-4-upgrade-process-restart-in-the-middle"&gt;Cluster Version Operator (CVO) documentation&lt;/a&gt; explains why that happens; it is by design.&lt;/p&gt; &lt;p&gt;At some time during the update, your web console session might expire because the update process restarts web console pods to use a new container image. You might even get a “server error” from the OpenShift router. If that happens, refresh your web browser, log in again (if needed), and navigate back to &lt;strong&gt;Administration—&gt;Cluster Settings&lt;/strong&gt; to continue monitoring the progress of your cluster update.&lt;/p&gt; &lt;p&gt;The stated OpenShift goal of 100% availability during updates does not mean that all HTTP requests to the web console and applications are successful. During an update, nodes are rebooted, pods are recreated, containers are stopped, and new containers are started. Load balancers might not react instantly and might send an occasional request to a container or a node that is not available. The next HTTP request should work.&lt;/p&gt; &lt;h2&gt;Is my OpenShift update done?&lt;/h2&gt; &lt;p&gt;When the update finishes, the web console shows your new current version and might also show that more updates are available (see Figure 5).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-5-version-4.5.17.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-5-version-4.5.17.png?itok=xb4Xv_FG" width="600" height="234" title="blog-5-version-4.5.17" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 5: The Cluster Settings screen after a successful update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;In my example, it looks like I still am unable to get to any 4.6 channel, but I see a single 4.5 release I could update to (see Figure 6).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-6-update-to-4.5.18.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-6-update-to-4.5.18.png?itok=dOdAdvfq" width="600" height="322" title="blog-6-update-to-4.5.18" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 6: Checking for newer versions on the Update Cluster screen after an update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So, I would repeat the process I've shown in this article to update to 4.5.18 and so on, in the hope of being able eventually to update to OpenShift 4.6. (I know that I do not need further updates, and I will explain later how I know that.)&lt;/p&gt; &lt;p&gt;Before you update again to the next z-stream release, refresh your browser tab. Your web browser might be displaying stale data from your previous cluster version. OpenShift 4.6 solves that particular issue and requires no browser refresh.&lt;/p&gt; &lt;h2&gt;Is my OpenShift update failing?&lt;/h2&gt; &lt;p&gt;I did a few cluster updates without any issues, from the same test environment. But one of my attempts displayed a scary, red exclamation icon and a “Failing” status, shown in Figure 7.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-7-failing.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-7-failing.png?itok=UHQ-cyEv" width="600" height="232" title="blog-7-failing" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 7: Status of "Failing".&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Calm down and notice that the status is “fail-&lt;em&gt;ing&lt;/em&gt;,” not “fail-&lt;em&gt;ed&lt;/em&gt;." The update process is still running. &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; clusters, applications, and operators can self-heal in a large number of scenarios. Sometimes the "Failing" message is caused by &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1884334"&gt;too short a timeout&lt;/a&gt; in the CVO. If that is the case, the message will fix itself with no action from you. And with no damage to your cluster and applications.&lt;/p&gt; &lt;p&gt;Do not panic, but give some time for OpenShift to heal itself. Be patient before you start collecting troubleshooting information and opening customer support tickets.&lt;/p&gt; &lt;h2&gt;Pending cluster operators&lt;/h2&gt; &lt;p&gt;If you click &lt;strong&gt;View details&lt;/strong&gt;, as shown in Figure 7, the web console shows you detailed information about the status of each cluster operator: Which ones have already finished updating and which ones are still performing their updates. Figure 8 shows that the &lt;code&gt;openshift-apiserver&lt;/code&gt; operator became degraded.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-8-degraded.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-8-degraded.png?itok=G3IkqUQE" width="600" height="337" title="blog-8-degraded" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 8: The cluster operators screen with a progress message showing a potential problem.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;I hope that the message “Cluster update &lt;em&gt;in progress&lt;/em&gt;," together with the less-alarming, blue information icon gives you some peace of mind: OpenShift is still performing the update; it has not failed at all.&lt;/p&gt; &lt;p&gt;Operators can become degraded for a while during updates and then recover by themselves. It is expected that, with each new OpenShift release, cluster operators become better at reporting their status and report fewer temporary failures.&lt;/p&gt; &lt;p&gt;Scrolling down, I can see that one of my API server pods is not running (see Figure 9). I know that this might happen when you update a Kubernetes deployment, so I decide to just give it some time to settle down.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-9-api-server.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-9-api-server.png?itok=f6zBNKwn" width="600" height="252" title="blog-9-api-server" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 9: A degraded pod on the Cluster Operators screen.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If I suspected that something was wrong, maybe because I saw other operators with errors, I would check the operator logs and cluster events to find a hint of a real unrecoverable error.&lt;/p&gt; &lt;p&gt;After a few minutes, the “Failing” state switches to “Update available” and the desired cluster version, 4.5.17, becomes the current version. My update finishes successfully, as shown in Figure 10.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-10-update-avail.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-10-update-avail.png?itok=5jpzTpRz" width="600" height="234" title="blog-10-update-avail" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 10: The Cluster Settings screen showing the current version after an update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;That “Failing” state could also switch to a new percent-complete message, as if the update process is just progressing and no failure ever happened. You might even see the installation go into a “Failing” state and then back to “Working towards” states a few times.&lt;/p&gt; &lt;p&gt;In the end, the changes you notice depend on how much attention you pay to the web console while your cluster is updating. Because I know the update is supposed to take time, I usually perform other tasks instead of staring at the OpenShift web console’s &lt;strong&gt;Cluster Settings&lt;/strong&gt; page. If something really bad happens during my update, I expect OpenShift cluster monitoring to alert me.&lt;/p&gt; &lt;h2&gt;Updating to a newer minor release&lt;/h2&gt; &lt;p&gt;You might not be able to update from your current 4.y.z release to any 4.y+1 release, using the web console, prior to OpenShift 4.6. It might be necessary to update to a newer 4.y.z+d before the web console shows a channel for the next minor release. You might even have to perform multiple z-stream updates.&lt;/p&gt; &lt;p&gt;In my sample scenario, I had to update from OpenShift 4.5.3 to 4.5.17 to get the possibility of switching to the stable-4.6 channel. With my cluster updated to 4.5.17, and also after a web browser page refresh, the web console offered me the choice of a stable channel for the next minor release of OpenShift (see Figure 11).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-11-update-4.6.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-11-update-4.6.png?itok=QkLUUgC6" width="600" height="452" title="blog-11-update-4.6" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 11: The Update Channel screen showing 4.6 releases.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To update to the next minor release, click on &lt;strong&gt;stable-4.6&lt;/strong&gt; to switch channels, click &lt;strong&gt;Update now&lt;/strong&gt;, and then select any of the available 4.6.z releases as the new OpenShift release for your cluster. The update process from now on is the same as a z-stream update.&lt;/p&gt; &lt;h2&gt;Is it too soon to update?&lt;/h2&gt; &lt;p&gt;The first time I tried to update from OpenShift 4.5 to 4.6, by switching from the stable-4.5 to the stable-4.6 channel, I got the disappointing “Version not found” status in Figure 12. It didn't make any difference if I didn't stop at 4.5.17, but continued to update to 4.5.18 or later.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-12-update-not-found.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-12-update-not-found.png?itok=28XM7I8T" width="600" height="204" title="blog-12-update-not-found" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 12: The update was not found.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The message means that the stable-4.6 channel does not include my current version. At that time, the stable-4.6 channel did not include 4.5.18 (nor 4.5.17, for that matter).&lt;/p&gt; &lt;p&gt;Figure 13 shows a fully updated OpenShift 4.5 cluster, according to its current release update channel (stable-4.5), so you can compare it to the previous figure. The “Up to date” status means that the channel lists my current release only as an update path destination, and not as a source of any path. So there are no updates available currently, but an update might become available in the future.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-13-up-to-date.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-13-up-to-date.png?itok=xdroVXi4" width="600" height="252" title="blog-13-up-to-date" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 13: The Cluster Settings screen when the OpenShift version is up to date.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If you find yourself in a similar scenario (that is, you switch to the stable channel of the next minor release, and find that no updates are available), Red Hat recommends that you switch back to a channel that lists your current release so you do not miss bug fixes and security updates. In my example, I would switch back to stable-4.5. Indeed, a few days later that channel got 4.5.19 and 4.5.20. But none of these releases are published to stable-4.6 as I write.&lt;/p&gt; &lt;p&gt;Because I tried checking only a few days after the first generally available (GA) release of OpenShift 4.6, all update paths were likely waiting for proof of stability from clusters using the fast channel.&lt;/p&gt; &lt;p&gt;If you find yourself in the same situation, you have two choices: Either check the stable-4.6 channel again from time to time, until you see a 4.6.z release update on the stable-4.6 channel, and revert back to the stable-4.5 after each check; or switch to the fast channel in the hope that there is an update path there.&lt;/p&gt; &lt;h2&gt;Using the fast channel&lt;/h2&gt; &lt;p&gt;In my case, after I switch to the fast-4.6 channel, I see that there are indeed updates available (see Figure 14).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-13-up-to-date.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-13-up-to-date.png?itok=xdroVXi4" width="600" height="252" title="blog-13-up-to-date" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 14: The Cluster Settings screen for the fast-4.6 channel shows updates available.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;And I could pick two releases to update from 4.5.18: 4.6.3 (not shown in Figure 15) and 4.6.4.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-15-update-to-4.6.4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-15-update-to-4.6.4.png?itok=UaBYqOvp" width="600" height="324" title="blog-15-update-to-4.6.4" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 15: Version 4.6.4 selected for update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 16 is proof that my test cluster finished its update to 4.6.4 using the fast channel. Notice the change in the look and feel of the web console. After OpenShift 4.7 is released, I will write a new article with new screenshots.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-16-version-4.6.4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-16-version-4.6.4.png?itok=o0wa5AO_" width="600" height="270" title="blog-16-version-4.6.4" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 16: The Cluster Settings screen after version 4.6.4 is selected for update.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Do not be afraid of updating your cluster using a fast channel if you need an update right now. Red Hat fully supports using all releases from the fast channel in production environments. Make the decision to switch, or wait based on your needs for these updates and the potential impacts of waiting a little longer to update.&lt;/p&gt; &lt;h2&gt;How to find which updates are available?&lt;/h2&gt; &lt;p&gt;You might not consider it intuitive that the OpenShift web console allows you to switch to a channel when no updates are available. It makes sense once you consider that you select a channel to signal your intent of getting updates from that channel. If you pick a very new channel, as I did, there might be very few update paths. Then it is no surprise that a given release is not in any of them.&lt;/p&gt; &lt;p&gt;Having to switch channels and wait for intermediate cluster updates before you find whether you can update to the desired OpenShift release could be frustrating. Fortunately, there are multiple ways of checking for available updates. OpenShift 4.6 allows you to find them before performing an update. But because I am still on 4.5, I have to search outside of the web console.&lt;/p&gt; &lt;p&gt;One way is to use the &lt;a href="https://ctron.github.io/openshift-update-graph/#stable-4.6"&gt;OpenShift Update Graph&lt;/a&gt;. It shows a nice-looking, though sometimes confusing, graph of all update paths available for the selected channel. For example, I got the results shown in Figure 17 in mid-November 2020.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-17-graph-stable.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-17-graph-stable.png?itok=_WWAX_iS" width="222" height="226" title="blog-17-graph-stable" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 17: Limited versions were available in the OpenShift Update Graph.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;At the time I generated Figure 17, there was no update path from any 4.5.z release to 4.6 in the stable channel. When I instead selected the fast-4.6 channel, I got the much richer graph in Figure 18.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-18-graph-fast.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-18-graph-fast.png?itok=cYwNojjy" width="600" height="490" title="blog-18-graph-fast" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 18: Numerous versions shown in the OpenShift Update Graph.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;To help you visualize the state of that graph at the time I captured the screenshots for this article, I colored all 4.5.z releases with arrows getting to any 4.6.z release and zoomed in so that this part of the graph is easier to read (see Figure 19).&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2020/11/blog-19-zoom-fast.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2020/11/blog-19-zoom-fast.png?itok=0z6VnSce" width="326" height="317" title="blog-19-zoom-fast" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 19: Focusing on 4.5.z versions in the OpenShift Update Graph.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Figure 19 makes it easier to see that I could update from 4.5.16, 4.5.17, 4.5.18, and 4.5.19 to an OpenShift 4.6 release using the fast-4.6 channel.&lt;/p&gt; &lt;h2&gt;Finding available updates from the shell&lt;/h2&gt; &lt;p&gt;Another way to list update paths from an OpenShift 4 update channel comes from &lt;a href="https://access.redhat.com/solutions/4583231"&gt;this article&lt;/a&gt;. The following example lists all updates available for 4.5.4 from the stable-4.5 channel. The last command includes a very long &lt;code&gt;jq&lt;/code&gt; filter. Make sure the entire filter is a single shell argument. Notice the single quotes around it.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export CURRENT_VERSION=4.5.4 $ export CHANNEL_NAME=stable-4.5 $ curl -sH 'Accept:application/json' "https://api.openshift.com/api/upgrades_info/v1/graph?channel=${CHANNEL_NAME}" | jq -r --arg CURRENT_VERSION "${CURRENT_VERSION}" '. as $graph | $graph.nodes | map(.version=='\"$CURRENT_VERSION\"') | index(true) as $orig | $graph.edges | map(select(.[0] == $orig)[1]) | map($graph.nodes[.].version) | sort_by(.)' [ "4.5.11", "4.5.13", "4.5.14", "4.5.15", "4.5.16", "4.5.17", "4.5.5", "4.5.6", "4.5.7", "4.5.8", "4.5.9", ]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;All those pipe signs (|) belong to the &lt;code&gt;jq&lt;/code&gt; filter. They are part of the fifth argument of the &lt;code&gt;jq&lt;/code&gt; command. Do not mistake them for shell pipes! Also note that the &lt;code&gt;jq&lt;/code&gt; filter sorts its output in a somewhat misleading way. It uses string ordering, not semantic version ordering. Notice that the most recent version, which was 4.5.17, appears in the middle of the output.&lt;/p&gt; &lt;p&gt;An alternative to writing that long &lt;code&gt;jq&lt;/code&gt; filter is using the &lt;a href="https://github.com/openshift/cincinnati/blob/master/hack/available-updates.sh"&gt;available-updates.sh&lt;/a&gt; script from the Cincinnati developers. The CVO uses the Cincinnati protocol to describe update channels.&lt;/p&gt; &lt;p&gt;Download the &lt;code&gt;available-updates.sh&lt;/code&gt; script and make it executable. Then set the &lt;code&gt;CHANNEL&lt;/code&gt; environment variable and pass the starting version as an argument. The following example lists what would be my options after I update to 4.5.17, using the fast-4.6 channel:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export CHANNEL=fast-4.6 $ ./available-updates.sh 4.5.17 4.5.18 quay.io/openshift-release-dev/ocp-release@sha256:72e3..f366 https://access.redhat.com/errata/RHBA-2020:4425 4.6.4 quay.io/openshift-release-dev/ocp-release@sha256:6681..86fc https://access.redhat.com/errata/RHBA-2020:4987&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;If I try the stable-4.6 channel I get an empty list, that is, &lt;code&gt;[]&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;By viewing the output of these commands, I was able to plan for two updates starting from 4.5.4: first to 4.4.17 and then to 4.6.4 using the fast channel.&lt;/p&gt; &lt;p&gt;As you might guess, many developers created their own visualization tools and scripts to report OpenShift cluster updates. An example is &lt;a data-pjax="#js-repo-pjax-container" href="https://github.com/pamoedom/ocp4upc"&gt;ocp4upc&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;OpenShift 4 updates do not have to be scary. The web console makes updates easy to do, and the underlying infrastructure provided by the CVO makes the process very reliable and dependable.&lt;/p&gt; &lt;p&gt;There are a few quirks in the way the web console handles updates up to OpenShift 4.5. Fortunately, OpenShift 4.6 solves most of them.&lt;/p&gt; &lt;p&gt;The OpenShift update process is very consistent with Kubernetes’s design patterns: You declare the desired state of your cluster and let Kubernetes converge the current state to the desired state.&lt;/p&gt; &lt;p&gt;For more information about how the OpenShift CVO and cluster operators handle cluster updates, please see the video &lt;a href="https://www.openshift.com/blog/red-hat-openshift-cluster-upgrades-and-application-operator-updates"&gt;Red Hat OpenShift: Cluster Upgrades and Application Operator Updates&lt;/a&gt; and also the excellent post from the official OpenShift blog: &lt;a href="https://www.openshift.com/blog/the-ultimate-guide-to-openshift-release-and-upgrade-process-for-cluster-administrators"&gt;The Ultimate Guide to OpenShift Release and Upgrade Process for Cluster Administrators&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;Thanks to Eric Rich and Mike Allmen for their reviews of drafts of this article. Also thanks to W. Trevor King and Scott Dodson for their many valuable comments improving the technical information in this article. If you find any errors and inaccuracies in this article, they are mine only despite their best efforts.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/27/how-update-newer-red-hat-openshift-4-releases" title="How to update to newer Red Hat OpenShift 4 releases"&gt;How to update to newer Red Hat OpenShift 4 releases&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Q17YrPMCT1I" height="1" width="1" alt=""/&gt;</summary><dc:creator>Fernando Lozano</dc:creator><dc:date>2021-05-27T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/27/how-update-newer-red-hat-openshift-4-releases</feedburner:origLink></entry><entry><title type="html">Writing fast constraints with OptaPlanner: the secret recipe</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eaW922tbOWw/writing-fast-constraints-with-optaplanner-the-secret-recipe.html" /><author><name>triceo</name></author><id>https://blog.kie.org/2021/05/writing-fast-constraints-with-optaplanner-the-secret-recipe.html</id><updated>2021-05-27T00:00:00Z</updated><content type="html">Do you want OptaPlanner to run faster? Do you want to increase your score calculation speed, reaching great solutions sooner? Let me show you how to optimize your constraints for performance and scalability. Turns out you only need to remember one advice: DO LESS The key to well-performing constraints is limiting the amount of data that flows through your Constraint Streams, which starts with . Consider a school timetabling problem, where a teacher must not have two overlapping lessons. This is how the lesson could look in Java: @PlanningEntity class Lesson { ... Teacher getTeacher() { ... } boolean overlaps(Lesson anotherLesson) { ... } boolean isCancelled() { ... } ... } The simplest possible Constraint Stream we could write to penalize all overlapping lessons would then look like: constraintFactory.from(Lesson.class) .join(Lesson.class) .filter((leftLesson, rightLesson) -&gt; !leftLesson.isCancelled() &amp;amp;&amp; !rightLesson.isCancelled() &amp;amp;&amp; leftLesson.getTeacher() .equals(rightLesson.getTeacher()) &amp;amp;&amp; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) What this Constraint Stream does is: 1. It creates all possible pairs of Lessons from the planning solution. 2. Then it all the lessons that are cancelled, where the teachers do not match, or which do not overlap. 3. It all the remaining lesson pairs. Do you see the problem here? The join creates a cross product between lessons, producing a match (also called a tuple) for every possible combination of two lessons, even though we know that many of these matches will not be penalized. This shows the problem in numbers: In order to process a thousand lessons, our constraint first creates a cross product of 1 million pairs, only to throw away pretty much all of them before penalizing! If we can reduce the size of the cross product by half, only half of the time will be spent processing it. This is where the original advice comes into play: do less, by avoiding unrestricted cross product. Here’s how. Table 1. Fast growth of cross product Number of lessons Number of possible pairs 10 100 100 10 000 1 000 1 000 000 FILTER BEFORE JOINING As you can see from the first example, cancelled lessons are eventually filtered out after the join. Let’s see if we can remove them from the cross product instead. For the first lesson in the join (also called “left”), this is straightforward; we simply bring the cancellation check before the join like so: constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()) .join(Lesson.class) .filter((leftLesson, rightLesson) -&gt; !rightLesson.isCancelled() &amp;amp;&amp; leftLesson.getTeacher() == rightLesson.getTeacher() &amp;amp;&amp; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) The cancelled lessons are no longer coming in from the left, which reduces the cross product. However, some cancelled lessons are still coming in from the right through the join. Here, we will use a little trick and join not with a Lesson class, but with a filtered nested Constraint Stream instead: constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()) .join( constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled())) .filter((leftLesson, rightLesson) -&gt; leftLesson.getTeacher() == rightLesson.getTeacher() &amp;amp;&amp; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) As you can see, we’ve created a new Constraint Stream from Lesson, filtering before it entered our join. We have now applied the same improvement on both the left and right sides of the join, making sure it only creates a cross product of lessons which we care about. But we can still do better! PREFER JOINERS TO FILTERS Filters are just a simple check if a tuple matches a predicate. If it does, it is sent downstream, otherwise the tuple is removed from the Constraint Stream. Each tuple needs to go through this check, and that means every pair of lessons will be evaluated. When a Lesson changes, all pairs with that Lesson will be re-evaluated, but not anymore: constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()) .join( constraintFactory.from(Lesson.class) .filter(lesson -&gt; !lesson.isCancelled()), Joiners.equal(Lesson::getTeacher)) .filter((leftLesson, rightLesson) -&gt; leftLesson.overlaps(rightLesson)) .penalize("Teacher lesson overlap", HardSoftScore.ONE_HARD) Notice that the Teacher equality check moved from the final filter to something called a Joiner. We are still saying the same thing – a Lesson pair will only be sent downstream if the Lessons share the same Teacher. Unlike the filter, this brings the performance benefit of indexing. Now when a Lesson changes, only the pairs with the matching Teacher will be re-evaluated. So even though the cross-product remains the same, we are doing much less work processing it. The final filter now only performs one operation on the final cross product, and the Lesson pairs that get this far are already trimmed down in the most efficient way possible. REMOVE MORE, EARLIER In some cases, you may have an option to pick the order of your Joiners. In these situations, you should put first the Joiner that will remove more tuples than the others. This will reduce the size of your cross products faster. Consider a new situation, where lessons also have rooms in which they happen. Although there are possibly dozens of teachers, there are only three rooms. Therefore the join should look like this: constraintFactory.from(Lesson.class) .join(Lesson.class, Joiners.equal(Lesson::getTeacher), Joiners.equal(Lesson::getRoom)) ... This way, we first create “buckets” for each of the many teachers, and these buckets will only contain a relatively small number of lessons per room. If we did it the other way around, there would be a small amount of large buckets, leading to much more iteration every time a lesson changes. For that reason, it is generally recommended putting Joiners based on enum fields or boolean fields last. CONCLUSION The key to efficient constraints is the reduction of cross product. There are three main ways of reducing cross product in Constraint Streams: 1. Filtering before joining. 2. Preferring Joiners earlier to filtering later. 3. Applying the more restrictive Joiners first. There are other optimization techniques as well, and we will discuss some of them in the future, but none of them will give as big a benefit as reducing the size of cross products. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eaW922tbOWw" height="1" width="1" alt=""/&gt;</content><dc:creator>triceo</dc:creator><feedburner:origLink>https://blog.kie.org/2021/05/writing-fast-constraints-with-optaplanner-the-secret-recipe.html</feedburner:origLink></entry><entry><title type="html">Tooling guide for Getting Started with Apache Camel in 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/CugRKVT82PY/tooling-guide-for-getting-started-with.html" /><author><name>CHRISTINA の J老闆</name></author><id>http://feedproxy.google.com/~r/blogspot/hFXzh/~3/N9sx2zTVps4/tooling-guide-for-getting-started-with.html</id><updated>2021-05-26T13:20:00Z</updated><content type="html">Getting Started with Apache Camel ? This post is for you. But I am not going to dive into how to write the Camel route, there are plenty of materials out there that do a better job than me. A good place to get started is the one and only , it gives you all the latest and greatest news from the community. If you want to start from the basics, I highly recommend Camel in Action II Book. It has everything you need to know about writing Camel. Or join the Camel community or chat  to ask questions, it's very friendly and welcoming. If you are a returning Camel rider, I would go through this , where it will get you up to speed on what to expect.  Another good resource is the page. I found the majority of the getting started enquiries can be found here.  This post will be about tools that can help you, when it comes to running a Camel application in its lifetime. From design, implementation, testing, deployment and monitoring. Of course this is strictly my opinion. Any suggestions or comments are welcome. Here is a quick collection of the tools I recommend.  DESIGN &amp;amp; IMPLEMENTATION There are several different IDEs out there that have language support for Camel. My current goto is the . VS Code itself has very primitive support for Java developers, but it comes with a large variety of extensions for you to customize it, and install all the tools you need. Speaking of extension, there is a must have… “”. It contains the essentials for developing Camel. I recommend checking out the for updates!  To begin a project, it’s always good to have some help to set the basic structure. You can either use the Project Initializer that comes with the Apache Camel by Red Hat Extension in VS Code that will generate the base project for you. Or you can always go to the Quarkus start coding page, adding the Camel dependencies to create the base project, but one downside of the Quarkus start coding page, it will not create the template extended RouteBuilder class for you.  No matter what runtime you choose, you are still writing Camel DSL (Domain Specific Language), you have the latest and greatest support from the camel extension, where it will help you with autocomplete, validating your Camel code.   Mapping data between formats can be tedious, especially with larger documents or more complex structure. But using the tooling can help you map between two data sources with a drag and drop user interface, so you will be able to visualize the mappings. The tool will generate an “.adm” file, place the file into your Camel project. You can then use the camel-atlasmap components to run the mapping.   from("servicenow:xxxxxx....")   .split().body()     .marshal().json()     .to("atlasmap:servicenow.adm")     .to("kafka:xxx?brokersxxx") RESTful API is another popular implementation in Camel, I highly recommend you take advantage of the Apicurio project, where it provides a GUI interface for designing the API contract. Making contract first application development a lot easier. For more details, take a look at my previous .  Another nice complements to the toolset is the , this is another extension in VS Code by Bruno, this can help you visualize the design of camel processing flow. So you will be able to see what your camel route does in a quick glance. TESTING  Camel can easily wire up unit tests in your preferred testing framework. My past experience has been great with using JUnit for creating my test cases.   What I normally would do is create a java Class for each test case (Extend “CamelTestSupport” class). Where it can kick off your camel route with mock endpoints, loading set of data or even stub out the actual endpoint When testing integration, introducing Behavior-Driven Development(BDD) Testing is a development practice, as it’s black box testing nature allows it to better mimic user input and expectation, and can test more complex scenarios when compared to Test-Driven Development(TDD). Consider using the “” for building out BDD test cases. You can define the test scenario descriptions with a "Given-When-Then" structure in a feature file, as well as a simple setup for mimicking the common endpoints such as Kafka, AMQP, JMS, REST… etc.   Feature: integration runs   Background:     Given load variables namespace.properties     Given URL: http://camel-hello-quarkus.${namespace}.svc.cluster.local:8080   Scenario: Checking GET Method     When send GET /prescription?profileid=123456     Then verify HTTP response body: {"profileid": 123456, "pharmancy": "CVS" }     Then receive HTTP 200 OK I have also been using a spinoff project from Citrus called YAKs to do my BDD testing on Kubernetes(OpenShift) platform. And I LOVED it. Simply because 1st, the lifecycle of the test was managed by the YAKs operator, meaning the test was run on a separate instance, that is where the client supposed the call, and also the YAKs operator takes in the feature, and does the test based on it. You can run it separately or plug it into your CI/CD pipeline. PLATFORM I have been using for managing all the running instances. It's just easier when there are hundreds of Camels running, it manages the scaling, resources, configuration and load-balancing for me. As well as a better deployment module (images). There are so many articles out there talking about the benefits of running a container &amp;amp; container management, so I won’t dive into it.  CI/CD Jenkin was on my list for a long time when it comes to building the pipeline for my Camel application. Basically using the maven jenkins plugin for compiling and deploying, and using the OpenShift plugin to do the canary releases. And recently, I have been using the Tekton pipeline, it’s built-in on OpenShift, so there is no need to install a separate instance and manage it. The Kubernetes platform itself will become the CI/CD platform itself. Here is an example of how it works with the Camel projects. I will write another deep dive into how it works. MONITORING With Camel 3, in order to collect and export the metrics, you will need to specifically add the microprofile-metrics dependency. And by using Prometheus to scrape metrics on the platform. It stores all scraped samples locally and aggregate the time series data. I then use Grafana to visualize the collected data, and create a dashboard to monitor all the camel routes. Also checkout this video and see how things work:&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/CugRKVT82PY" height="1" width="1" alt=""/&gt;</content><dc:creator>CHRISTINA の J老闆</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/blogspot/hFXzh/~3/N9sx2zTVps4/tooling-guide-for-getting-started-with.html</feedburner:origLink></entry><entry><title type="html">JGroups 5.1.7 released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_xduhFXat4o/jgroups-517-released.html" /><author><name>Bela Ban</name></author><id>http://belaban.blogspot.com/2021/05/jgroups-517-released.html</id><updated>2021-05-26T08:06:00Z</updated><content type="html">I'm happy to announce that 5.1.7 has been released! The major new features are FD_SOCK2 [1] and VERIFY_SUSPECT2 [2]. The complete list of features and bug fixes is at [4]. Here's a short description of the major changes/additions: FD_SOCK2 This is a rewrite of FD_SOCK, which was created 20 (!) years ago. The old protocol has worked surprisingly well, given its brittle and complex design. FD_SOCK2 should be much more robust, as I've eliminated the cache between ports and members, and code which maintains this cache. Also, FD_SOCK2 (re-)uses NioServer, which means that we'll use 1 (select) thread instead of 3 in FD_SOCK. Compared to FD_SOCK's 1235 LOC, FD_SOCK2 has 723 LOC with the same functionality. VERIFY_SUSPECT2 The major change over VERIFY_SUSPECT is that VERIFY_SUSPECT2 bundles SUSPECT events sent up the stack. This reduces the where view installation runs into a timeout waiting for acks from crashed members. When X crashed, and then Y crashed a few milliseconds later, then VERIFY_SUSPECT would have sent up events SUSPECT(X) and then SUSPECT(Y), whereas VERIFY_SUSPECT2 sends up SUSPECT(X,Y) *if* X and Y crashed in the same time window (1s by default). This speeds up the installation of the new view, especially when multiple members have crashed. NO NEED TO USE JMX= OR OP= IN PROBE This is only syntatic sugar, but now we can shorten probe.sh jmx=UDP.bind to probe.sh UDP.ping and probe.sh op=TCP.printConnections to probe.sh TC.printConnections[]. This comes in handy when switching between attributes and operations. JIRA: [3] [1] [2] [3] [4]&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_xduhFXat4o" height="1" width="1" alt=""/&gt;</content><dc:creator>Bela Ban</dc:creator><feedburner:origLink>http://belaban.blogspot.com/2021/05/jgroups-517-released.html</feedburner:origLink></entry><entry><title>Real-time debugging in Tekton pipelines</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/PLrlPxyOTfA/real-time-debugging-tekton-pipelines" /><author><name>Vibhav Bobade</name></author><id>f773e1ba-caea-4edd-8bc7-9b838c035aab</id><updated>2021-05-26T07:00:00Z</updated><published>2021-05-26T07:00:00Z</published><summary type="html">&lt;p&gt;Debugging &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;CI/CD&lt;/a&gt; pipelines isn't always easy. This is especially true when a pipeline takes a long time to run, and the failing part you want to debug runs at the end of the pipeline. A feature introduced in a recent &lt;a href="https://tekton.dev/"&gt;Tekton&lt;/a&gt; enhancement proposal (TEP) would let users stop the pipeline at any Step and debug in real time.&lt;/p&gt; &lt;p&gt;This article looks at debugging TaskRuns in Tekton, the open source framework that integrates with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; to create cloud-native CI/CD pipelines. You can learn more about the basics of Tekton in &lt;a href="https://developers.redhat.com/blog/2020/04/30/creating-pipelines-with-openshift-4-4s-new-pipeline-builder-and-tekton-pipelines/"&gt;this article by Joel Lord&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The proposal, &lt;a href="https://github.com/tektoncd/community/blob/main/teps/0042-taskrun-breakpoint-on-failure.md"&gt;TEP-0042&lt;/a&gt;, outlines this feature with a proof of concept that describes how Tekton's composability and &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container support&lt;/a&gt; enable this functionality. For a thorough overview of these concepts, watch the talk, &lt;a href="https://www.youtube.com/watch?v=iz9_omZ0ctk"&gt;Russian Doll: Extending Containers with Nested Processes&lt;/a&gt; by Christie Wilson (Google) and Jason Hall (Red Hat).&lt;/p&gt; &lt;h2&gt;Debugging TaskRuns: TL;DR&lt;/h2&gt; &lt;p&gt;Debugging TaskRuns in Tekton is possible because of the composability provided by container-based pipelines it helps the user create. A Task runs as a Pod, and each Step in a Task runs in a container. With each Step running in a container, we can be sure that the delta of change in the container environment (which is not shared between Steps) is directly associated with the Step itself and nothing else. Anything else that might happen is a side effect, e.g., due to the injection of a sidecar container to the TaskRun. This makes Tekton great for debugging pipelines, as the cost to spin up a container is definitely far less than spinning up a cloud virtual machine (VM).&lt;/p&gt; &lt;p&gt;With this in mind, TEP-0042 would extend the TaskRun Step life cycle (responsible for orchestrating TaskRun containers to run serially) and add capabilities to pause a TaskRun Step after a failure occurs.&lt;/p&gt; &lt;h2&gt;Modifying the life of a Step&lt;/h2&gt; &lt;p&gt;The life of a Step currently looks something like Figure 1.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/Screenshot-from-2021-04-28-13-14-36.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/Screenshot-from-2021-04-28-13-14-36.png?itok=Cqwq_4AJ" width="516" height="466" alt="Diagram showing the life of a Step in Tekton: e.Go(), Wait for postFile, write err postFile, return err, exit." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The life of a Step in Tekton.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The Step starts running when &lt;code&gt;e.Go()&lt;/code&gt; runs. This is where Tekton invokes the entry point of the Step in the TaskRun and the child process (which is the actual Step) runs. If the child process runs successfully, we write a &lt;code&gt;postFile&lt;/code&gt; that is used as a flag to convey the same. If it fails, we write an &lt;code&gt;err postFile&lt;/code&gt;, which conveys a similar message.&lt;/p&gt; &lt;p&gt;To halt this Step on failure, we must understand which parts of the Step react when the failure occurs; this is the &lt;code&gt;write err postFile&lt;/code&gt; and &lt;code&gt;exit&lt;/code&gt; shown in Figure 1. When a Step fails, the failure is marked by writing a &lt;code&gt;&lt;step-no&gt;.err&lt;/code&gt; file to &lt;code&gt;/tekton/tools/&lt;/code&gt; directory in the Step container, which is shared with other containers in the Pod. This file is written by the background job in the entry point. The &lt;code&gt;&lt;step-no&gt;.err&lt;/code&gt; file also lets the subsequent Steps know that there has been a failure, and eventually exits the TaskRun.&lt;/p&gt; &lt;p&gt;This mechanism needs to be updated to support the discovery of Step failures and the ability to stop the Steps before it exits. This requires disabling the &lt;code&gt;write err postFile&lt;/code&gt;. Instead of exiting the Step, it will wait for a flag that would exit the Step from the suspended state. The updated flow would look something like the diagram shown in Figure 2.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/04/Screenshot-from-2021-04-28-13-24-40.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/04/Screenshot-from-2021-04-28-13-24-40.png?itok=MyFfl93M" width="505" height="440" alt="Diagram showing proposed Step life cycle in Tekton when TaskRun failure occurs: e.Go(), Wait for postFile, return err, Wait for breakpoint exit." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The proposed update to the Step life cycle in Tekton when TaskRun failure occurs.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once the Step is halted, the client can access the container environment for debugging.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In practice, the debugging solution is more nuanced than the overview provided here. Read &lt;a href="https://github.com/tektoncd/community/blob/main/teps/0042-taskrun-breakpoint-on-failure.md"&gt;the full TEP-0042 proposal&lt;/a&gt; for details.&lt;/p&gt; &lt;p&gt;This topic is also the subject of a cdCon 2021 talk: &lt;a href="https://cdcon2021.sched.com/event/iotA/houston-weve-got-a-problem-how-to-debug-your-pipeline-in-tekton-in-realtime-vibhav-bobade-vincent-demeester-red-hat"&gt;Houston, We've Got a Problem!: How to Debug your Pipeline in Tekton&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The debugging feature is expected to be available in Tekton later this year, with support across different Tekton clients, including the &lt;a href="https://github.com/openshift/pipelines-tutorial"&gt;Red Hat OpenShift Pipelines&lt;/a&gt; command-line interface (&lt;code&gt;tkn&lt;/code&gt;) and the Tekton dashboard. Get ready to debug Tekton pipelines in real time.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/26/real-time-debugging-tekton-pipelines" title="Real-time debugging in Tekton pipelines"&gt;Real-time debugging in Tekton pipelines&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/PLrlPxyOTfA" height="1" width="1" alt=""/&gt;</summary><dc:creator>Vibhav Bobade</dc:creator><dc:date>2021-05-26T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/26/real-time-debugging-tekton-pipelines</feedburner:origLink></entry><entry><title type="html">Getting started with TrustyAI in only 15 minutes</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5BNEeud5uL4/getting-started-with-trustyai-in-only-15-minutes.html" /><author><name>Jacopo Rota</name></author><id>http://feeds.athico.com/~r/droolsatom/~3/0i1ugm-hPb4/getting-started-with-trustyai-in-only-15-minutes.html</id><updated>2021-05-26T06:32:57Z</updated><content type="html">Hi Kogito folks, In the previous blogposts we demonstrated how to deploy a Kogito service together with the TrustyAI infrastructure on an OpenShift cluster . If you are new to TrustyAI, we suggest you read this introduction: In this blogpost, we’d like to demonstrate how to get started with TrustyAI in ~15 minutes. In order to start the demo, you will need the following applications installed on your laptop git &gt;= 2.27.0 docker &gt;= 20.10.3 docker-compose &gt;= 1.25.2 java &gt;= 11 maven &gt;= 3.6.3 Note that also previous versions of the applications might work, but they were not tested. The first step is to clone our kogito-examples repository (if you haven’t it yet) with git clone https://github.com/kiegroup/kogito-examples.git and checkout the stable branch cd kogito-examples git checkout stable and build a Kogito decision service with the tracing-addon and the monitoring-addon. For example kogito-examples/dmn-tracing-quarkus is already prepared, so you can compile and package it with mvn clean package -DskipTests -f dmn-tracing-quarkus/pom.xml and then copy the generated grafana dashboards to the docker-compose directory with cp dmn-tracing-quarkus/target/classes/META-INF/resources/monitoring/dashboards/* trusty-demonstration/docker-compose/grafana/provisioning/dashboards/ and then build the docker image with docker build -t org.kie.kogito/dmn-tracing-quarkus:1.0 dmn-tracing-quarkus/ In this example we tag the image org.kie.kogito/dmn-tracing-quarkus:1.0, but you can use another tag. The second step is to run the Kogito service together with the TrustyAI infrastructure. In order to do that, change your current directory to kogito-examples/trusty-demontration/docker-compose . With your preferred editor, edit the file docker-compose.yaml and replace the line 48 with the tag of the docker image you have just created (we used org.kie.kogito/dmn-tracing-quarkus:1.0 for example) The final step is just about running the docker-compose script with (depending on your setup, you might need to run this command with sudo ) docker-compose up The services are available at the following endpoints: * Kogito application: localhost:8080 * AuditUI: localhost:1337 * Grafana: localhost:3000 You can now open localhost:8080/swagger-ui and execute some POST requests to the LoanEligibility with the following payload { "Bribe": 1000, "Client": { "age": 43, "existing payments": 100, "salary": 1950 }, "Loan": { "duration": 15, "installment": 180 }, "SupremeDirector": "Yes" } You should now see the executions in the AuditUI and the monitoring data in Grafana. The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5BNEeud5uL4" height="1" width="1" alt=""/&gt;</content><dc:creator>Jacopo Rota</dc:creator><feedburner:origLink>http://feeds.athico.com/~r/droolsatom/~3/0i1ugm-hPb4/getting-started-with-trustyai-in-only-15-minutes.html</feedburner:origLink></entry><entry><title type="html">Quarkus 1.13.5.Final released - Maintenance release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/dNlmPatTwes/" /><author><name /></author><id>https://quarkus.io/blog/quarkus-1-13-5-final-released/</id><updated>2021-05-26T00:00:00Z</updated><content type="html">We released 1.13.5.Final today with a new set of bugfixes for our 1.13 release. 1.13.5.Final is a safe upgrade for everyone using Quarkus 1.13. If you are not using 1.13 already, please refer to the 1.13 migration guide. What’s new? Maven 3.8.1 Given there are a couple of CVEs in...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/dNlmPatTwes" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/quarkus-1-13-5-final-released/</feedburner:origLink></entry><entry><title>Red Hat Universal Base Image and Docker Hub: Why should developers care?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/JKZGyAd5iK4/red-hat-universal-base-image-and-docker-hub-why-should-developers-care" /><author><name>Don Schenck</name></author><id>22027747-b1bd-44d3-919b-8b448323401c</id><updated>2021-05-25T19:39:15Z</updated><published>2021-05-25T19:39:15Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/rhel/ubi"&gt;Red Hat Universal Base Image&lt;/a&gt; (UBI) is Red Hat's &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt;-ready operating system image that allows you to build smaller images for use in container-based systems. With the announcement that &lt;a href="https://www.redhat.com/en/about/press-releases/red-hat-brings-red-hat-universal-base-image-docker-hub"&gt;UBI images are now “Verified Publisher” images on Docker Hub&lt;/a&gt;, developers now have nothing standing between them and their application running on &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL). Freely redistributable &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; images that are OCI-compliant (&lt;a href="https://opencontainers.org/"&gt;Open Container Initiative&lt;/a&gt;) and ready for &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; can be prepared with a simple &lt;code&gt;FROM&lt;/code&gt; command in your Dockerfile.&lt;/p&gt; &lt;h2&gt;Why stop at one UBI image?&lt;/h2&gt; &lt;p&gt;What's more, there isn't just one UBI image available; there are several. As the press release notes, four are immediately available at Docker Hub:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Standard&lt;/strong&gt; provides the necessary runtimes and YUM repositories to build, deploy, and share UBI-based containers.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Minimal&lt;/strong&gt; is a UBI image that provides only the bare essentials needed for a lightweight RHEL-based image.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multi-service&lt;/strong&gt; is designed for container images that are intended to run multiple application services by also including systemd.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Micro&lt;/strong&gt;, newly announced with &lt;a href="https://www.redhat.com/en/blog/rhel-84-brings-continuous-stability-plus-innovation"&gt;Red Hat Enterprise Linux 8.4&lt;/a&gt;, delivers the smallest UBl footprint for &lt;a href="https://developers.redhat.com/topics/edge-computing"&gt;edge computing&lt;/a&gt; and other remote applications.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;The advantage of UBI&lt;/h2&gt; &lt;p&gt;These images make life much easier as a developer. No longer do I need to log in to my Red Hat account and use their registry. Instead, my (&lt;a href="https://developers.redhat.com/topics/dotnet/"&gt;.NET Core&lt;/a&gt; application, for example) Dockerfile can look like this:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;FROM redhat/ubi8-minimal RUN mkdir dotnetmvc WORKDIR /dotnetmvc ADD ./bin/Release/net5.0/rhel.8-x64/publish/. . EXPOSE 5000 CMD ["./dotnetmvc"]&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;code&gt;FROM redhat/ubi8-minimal&lt;/code&gt; and I'm good to go. What's great is that this can be distributed and my application will run on enterprise-grade RHEL, no matter where it's being hosted.&lt;/p&gt; &lt;p&gt;As an aside to .NET developers: By publishing a standalone application and using this UBI8-minimal base image (instead of the older UBI image with .NET included), I took my .NET application's image from 831MB down to 205MB. This is a good opportunity to experiment with different base images to reduce image size.&lt;/p&gt; &lt;h2&gt;Who cares?&lt;/h2&gt; &lt;p&gt;When it comes to Red Hat's UBI images being available at Docker Hub, the bottom line is this: As a developer, you no longer &lt;em&gt;need&lt;/em&gt; to care. Pull the UBI image and keep coding.&lt;/p&gt; &lt;h2&gt;Want more info?&lt;/h2&gt; &lt;p&gt;My colleague, Mike Guerette, wrote &lt;a href="https://developers.redhat.com/books/red-hat-universal-base-images-ubi"&gt;the book about UBI&lt;/a&gt;, and you can download it for free.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/25/red-hat-universal-base-image-and-docker-hub-why-should-developers-care" title="Red Hat Universal Base Image and Docker Hub: Why should developers care?"&gt;Red Hat Universal Base Image and Docker Hub: Why should developers care?&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/JKZGyAd5iK4" height="1" width="1" alt=""/&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2021-05-25T19:39:15Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/25/red-hat-universal-base-image-and-docker-hub-why-should-developers-care</feedburner:origLink></entry><entry><title>Capture detailed analytics with the custom metrics policy in Red Hat 3scale API Management</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/yGDPWilbp8s/capture-detailed-analytics-custom-metrics-policy-red-hat-3scale-api-management" /><author><name>Chamal Abeywardhana</name></author><id>909036ae-654c-4c29-9519-37805ff4239e</id><updated>2021-05-25T07:00:00Z</updated><published>2021-05-25T07:00:00Z</published><summary type="html">&lt;p&gt;Developers use &lt;a href="https://developers.redhat.com/products/3scale/overview"&gt;Red Hat 3scale API Management&lt;/a&gt; to manage APIs through a gateway called &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.3/html/deployment_options/apicast-overview"&gt;APIcast&lt;/a&gt;. APIcast includes many out-of-the-box &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/administering_the_api_gateway/apicast_policies#standard-policies"&gt;policies&lt;/a&gt; that can be configured to extend its default behavior. A new addition to APIcast, the custom metrics policy, provides another way to track metrics that are valuable to your business via the 3scale analytics engine.&lt;/p&gt; &lt;p&gt;The custom metrics policy was introduced in 3scale API Management 2.9. I was intrigued to learn how to configure this policy, and wanted to understand its potential use scenarios. This article introduces one way to take advantage of the custom metrics policy, using a metric that tracks specific HTTP response status codes as an example scenario. The default analytics in 3scale just capture the response statuses into buckets of 2xx, 4xx, and so on. If you want to capture specific status codes such as 203 or 403, you can use this &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/administering_the_api_gateway/apicast_policies#custom-metrics"&gt;custom metrics policy&lt;/a&gt;.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: 3scale analytics represent only cumulative metrics. Therefore, complex metric tracking for averages, etc., should be done with other tools.&lt;/p&gt; &lt;h2&gt;Setting up the custom metrics policy&lt;/h2&gt; &lt;p&gt;This section explains the prerequisites for the scenario shown in the article, followed by setup. The section that follows explains the end-to-end flow.&lt;/p&gt; &lt;h3&gt;Prerequisites&lt;/h3&gt; &lt;p&gt;To complete this tutorial you will need the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;3scale API Management 2.9 on-premises deployment.&lt;/li&gt; &lt;li&gt;A private backend API that returns HTTP status codes. For the purpose of this article, use the &lt;a href="https://github.com/chamalabey/3scale-private-api"&gt;3scale-private-api&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;A binary download of the &lt;a href="https://ngrok.com/download"&gt;ngrok&lt;/a&gt; secure tunneling service.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Setup&lt;/h3&gt; &lt;p&gt;Install and deploy the &lt;a href="https://github.com/chamalabey/3scale-private-api/blob/master/README.md"&gt;3scale-private-api backend&lt;/a&gt;. This simple application will return a response with the status code that you specify by passing a status code in the request URL. For instance, if you include the parameter &lt;code&gt;/status/203&lt;/code&gt; in the URL, the backend returns a status of 203.&lt;/p&gt; &lt;p&gt;The example application listens for requests on port 3000. Expose that port to the internet via the ngrok application by executing the following command:&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The public URL generated by ngrok is valid for only eight hours on the free tier.&lt;/p&gt; &lt;pre&gt; $ ./ngrok http 3000&lt;/pre&gt; &lt;p&gt;When you execute the previous command, you will get an output similar to the following:&lt;/p&gt; &lt;pre&gt; Forwarding http://8fcf5e08d900.ngrok.io -&gt; localhost:30 Forwarding https://8fcf5e08d900.ngrok.io -&gt; localhost:3000&lt;/pre&gt; &lt;p&gt;Copy the secure HTTPS URL from the output and specify it as your backend, pasting it into the &lt;strong&gt;Private Base URL&lt;/strong&gt; field, as shown in Figure 1.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/01/image2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/01/image2.png?itok=rmjTdXb5" width="600" height="453" title="image2" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Choosing the private base URL for the backend.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If the backend is not configured for your API product, configure it for the product as shown in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/getting_started/first-steps#adding-backends-product"&gt;3scale documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Configure a new metric on the product to be updated based on the response code. You can create any number of metrics with the &lt;strong&gt;System name&lt;/strong&gt; field of &lt;code&gt;status-&lt;em&gt;HTTP-STATUS-CODE&lt;/em&gt;&lt;/code&gt; for all the HTTP status codes you would like to capture, as shown in Figure 2.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/01/image6.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/01/image6.png?itok=wrnY9flF" width="600" height="349" title="image6" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: Setting the status that you would like the backend to return.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Add the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.9/html/administering_the_api_gateway/apicast_policies#custom-metrics"&gt;custom metrics policy&lt;/a&gt; to your service configuration, as shown in Figure 3.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/01/image7.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/01/image7.png?itok=R4FuICH5" width="600" height="283" title="image7" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: Selecting the custom metrics policy.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Configure the policy as shown in Figure 4.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/blog/2021/01/image3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/blog/2021/01/image3.png?itok=5STXz8rP" width="423" height="1123" title="image3" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: Configuring the policy.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Update the policy chain and promote the service configuration to the API product's staging and production environments.&lt;/p&gt; &lt;h2&gt;End-to-end flow&lt;/h2&gt; &lt;p&gt;Make sure that the &lt;a href="https://github.com/chamalabey/3scale-private-api/blob/master/README.md"&gt;private API backend&lt;/a&gt; application is running and exposed via ngrok, and that the private base URL of the service backend is correctly configured to reflect the URL generated by ngrok.&lt;/p&gt; &lt;p&gt;Make a request to APIcast with the correct credentials to invoke the service configured. Note that the following request URL matches the metric &lt;code&gt;status-203&lt;/code&gt;. You have to include the &lt;code&gt;-k&lt;/code&gt; option if you have self-signed certificates:&lt;/p&gt; &lt;pre&gt; $ curl "https://api-3scale-apicast-staging.apps-crc.testing:443/status/203?user_key=&lt;em&gt;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&lt;/em&gt;" -k&lt;/pre&gt; &lt;p&gt;You should receive a response similar to the following:&lt;/p&gt; &lt;pre&gt; status code 203 set to the header&lt;/pre&gt; &lt;p&gt;Make another request as follows to update the &lt;code&gt;status-303&lt;/code&gt; metric:&lt;/p&gt; &lt;pre&gt; $ curl "https://api-3scale-apicast-staging.apps-crc.testing:443/status/303?user_key=&lt;em&gt;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&lt;/em&gt;" -k&lt;&lt;/pre&gt; &lt;p&gt;Go to &lt;strong&gt;Product Analytics—&gt;Traffic&lt;/strong&gt; to check whether the metrics about return status codes are updated accordingly.&lt;/p&gt; &lt;p&gt;If you have added more metrics, they also are updated based on status codes you have passed in.&lt;/p&gt; &lt;h2&gt;Additional notes&lt;/h2&gt; &lt;p&gt;To find out all the liquid variables available in each step of APIcast, you can use the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.8/html/administering_the_api_gateway/apicast_policies#liquid_context_debug"&gt;Liquid Context Debug&lt;/a&gt; policy. This is useful if you want to use the available variables to write complex logical expressions. (We won't cover that topic in this article.)&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.8/html/administering_the_api_gateway/apicast_policies#liquid_context_debug"&gt;Liquid Context Debug&lt;/a&gt; policy does not work when you have more than one backend in your product configuration.&lt;/p&gt; &lt;p&gt;Here is how to inspect the host header using a liquid expression:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Add the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_3scale_api_management/2.8/html/administering_the_api_gateway/apicast_policies#liquid_context_debug"&gt;Liquid Context Debug&lt;/a&gt; policy to the policy chain. The policy needs to be placed before the APIcast policy or the upstream policy in the policy chain.&lt;/li&gt; &lt;li&gt;Make a request to the APIcast as you normally do.&lt;/li&gt; &lt;li&gt;The response will be in JSON, with additional variables available in each context. Here is a snippet from an example request: &lt;pre&gt; "http_method": "GET", "already_seen": "ALREADY SEEN - NOT CALCULATING AGAIN TO AVOID CIRCULAR REFS", "remote_port": "52672", "remote_addr": "10.116.0.1", "current": { "host": "api-3scale-apicast-staging.apps-crc.testing", "original_request": { "current": { "host": "api-3scale-apicast-staging.apps-crc.testing", "query": "user_key=267c255c50b842ca0ebf9cf4ee2bfd1e", "path": "\/", "headers": { "host": "api-3scale-apicast-staging.apps-crc.testing", "x-forwarded-host": "api-3scale-apicast-staging.apps-crc.testing", "x-forwarded-for": "192.168.130.1", "user-agent": "curl\/7.66.0", "forwarded": "for=192.168.130.1;host=api-3scale-apicast-staging.apps-crc.testing;proto=https", "x-forwarded-port": "443", "x-forwarded-proto": "https", "accept": "*\/*" }, "uri": "\/", "server_addr": "10.116.0.83" }, "next": { "already_seen": "ALREADY SEEN - NOT CALCULATING AGAIN TO AVOID CIRCULAR REFS" } }, &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Note the variables such as &lt;code&gt;host&lt;/code&gt;, &lt;code&gt;query&lt;/code&gt;, and &lt;code&gt;headers&lt;/code&gt; available under the &lt;code&gt;original_request&lt;/code&gt; variable. You can access those values using liquid tags in policies that support liquid values. For example, you can access the original hostname by using the liquid tag &lt;code&gt;{{original_request['host']}}&lt;/code&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, you have learned how to use the custom metrics policy to capture analytics for specific status codes, which 3scale API Management by default does not individually capture. You also learned how to use the Liquid Context Debug policy to find out the variables available for use in APIcast policies.&lt;/p&gt; &lt;p&gt;I hope this guide provided you with sufficient tools to implement a solution similar to the one described. Feel free to comment with any suggestions to improve this content.&lt;/p&gt; &lt;h2&gt;What’s next?&lt;/h2&gt; &lt;p&gt;Use this guide as a reference to track alternative metrics in the 3scale analytics, and don't hesitate to contact the &lt;a href="https://access.redhat.com/support"&gt;support team&lt;/a&gt; or open an issue on the APIcast GitHub repository with questions.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/05/25/capture-detailed-analytics-custom-metrics-policy-red-hat-3scale-api-management" title="Capture detailed analytics with the custom metrics policy in Red Hat 3scale API Management "&gt;Capture detailed analytics with the custom metrics policy in Red Hat 3scale API Management &lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/yGDPWilbp8s" height="1" width="1" alt=""/&gt;</summary><dc:creator>Chamal Abeywardhana</dc:creator><dc:date>2021-05-25T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/05/25/capture-detailed-analytics-custom-metrics-policy-red-hat-3scale-api-management</feedburner:origLink></entry></feed>
